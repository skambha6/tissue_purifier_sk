{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "split-cleaner",
   "metadata": {},
   "source": [
    "# Extract all the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd4690",
   "metadata": {},
   "source": [
    "Similar to notebook2 but we package everything inside a for loop to exctract features for all tissues based on all pretrained models.\n",
    "\n",
    "Further analysis of embeddings produced by all models can be found in the code to reproduce figures from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b029c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO REMOVE when notebook is stable\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-logic",
   "metadata": {},
   "source": [
    "### Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "living-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tarfile\n",
    "import os\n",
    "from anndata import read_h5ad\n",
    "\n",
    "# tissue_purifier import\n",
    "import tissue_purifier as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c3b85",
   "metadata": {},
   "source": [
    "### Download the example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7f49b7-77b6-4612-98b2-c0484b1e66d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wt3_dm.h5ad', 'wt1_dm.h5ad', 'diabetes2_dm.h5ad', 'wt2_dm.h5ad', 'diabetes1_dm.h5ad', 'diabetes3_dm.h5ad']\n"
     ]
    }
   ],
   "source": [
    "## replace with your own path\n",
    "data_destination_folder = \"../../TissueMosaic_Figures/TissueMosaic_data/testis_anndata_corrected_doubletmode_annotated/\"\n",
    "\n",
    "# Make a list of all the h5ad files in the data_destination_folder\n",
    "fname_list = []\n",
    "for f in os.listdir(data_destination_folder):\n",
    "    if f.endswith('.h5ad'):\n",
    "        fname_list.append(f)\n",
    "print(fname_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6af91f-a1b2-4867-9641-78db3eea5479",
   "metadata": {},
   "source": [
    "### copy the data into a new folder for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1e35b3-b3fd-4886-9aa0-fd3d0ee125a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testis_anndata_featurized/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "new_data_destination_folder = \"testis_anndata_featurized/\"\n",
    "shutil.copytree(data_destination_folder, new_data_destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee36ef8-707b-4f87-873b-51906afa7e6a",
   "metadata": {},
   "source": [
    "### Download all the checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f58da9-a025-4536-8b44-b828f9db6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_ckpts = [\"testis_dino.pt\", \"testis_barlow.pt\", \"testis_simclr.pt\", \"testis_vae.pt\"]\n",
    "all_models = [\"dino\", \"barlow\", \"simclr\", \"vae\"] \n",
    "## replace with your own path\n",
    "ckpt_path = os.path.abspath(\"../../model_checkpoints/testis/\")\n",
    "all_ckpts_dest = []\n",
    "for ckpt in all_ckpts:\n",
    "    ckpt_dest= os.path.join(ckpt_path, ckpt)\n",
    "    all_ckpts_dest.append(ckpt_dest)\n",
    "    \n",
    "# print(all_ckpts_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa30a0b",
   "metadata": {},
   "source": [
    "### Extract features with all the models (Barlow, Simclr, Dino, Vae) and ncv_k for multiple k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846cfb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Model ---> dino /home/skambha6/chenlab/tissue_purifier/model_checkpoints/testis/testis_dino.pt\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements ---> 29178\n",
      "mean and median spacing 15.90507495709278, 15.497339152935078\n",
      "The dense shape of the image is -> torch.Size([9, 1178, 1175])\n",
      "number of elements ---> 27840\n",
      "mean and median spacing 16.009033744023068, 15.768961335552781\n",
      "The dense shape of the image is -> torch.Size([9, 1160, 1143])\n",
      "number of elements ---> 29607\n",
      "mean and median spacing 15.810478612949094, 15.727658385209352\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 855])\n",
      "number of elements ---> 30132\n",
      "mean and median spacing 16.353857684013548, 15.931447916615909\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1180])\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n",
      "----------\n",
      "Model ---> barlow /home/skambha6/chenlab/tissue_purifier/model_checkpoints/testis/testis_barlow.pt\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements ---> 29178\n",
      "mean and median spacing 15.90507495709278, 15.497339152935078\n",
      "The dense shape of the image is -> torch.Size([9, 1178, 1175])\n",
      "Key ncv_k10 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k20 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k50 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k100 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k200 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k500 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "number of elements ---> 27840\n",
      "mean and median spacing 16.009033744023068, 15.768961335552781\n",
      "The dense shape of the image is -> torch.Size([9, 1160, 1143])\n",
      "Key ncv_k10 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k20 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k50 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k100 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k200 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k500 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "number of elements ---> 29607\n",
      "mean and median spacing 15.810478612949094, 15.727658385209352\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 855])\n",
      "Key ncv_k10 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k20 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k50 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k100 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k200 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k500 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "number of elements ---> 30132\n",
      "mean and median spacing 16.353857684013548, 15.931447916615909\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1180])\n",
      "Key ncv_k10 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k20 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k50 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k100 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k200 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k500 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n",
      "Key ncv_k10 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k20 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k50 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k100 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k200 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k500 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n",
      "Key ncv_k10 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k20 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k50 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k100 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k200 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "Key ncv_k500 already present in spot dictionary. Set overwrite to True to overwrite\n",
      "----------\n",
      "Model ---> simclr /home/skambha6/chenlab/tissue_purifier/model_checkpoints/testis/testis_simclr.pt\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements ---> 29178\n",
      "mean and median spacing 15.90507495709278, 15.497339152935078\n",
      "The dense shape of the image is -> torch.Size([9, 1178, 1175])\n",
      "number of elements ---> 27840\n",
      "mean and median spacing 16.009033744023068, 15.768961335552781\n",
      "The dense shape of the image is -> torch.Size([9, 1160, 1143])\n",
      "number of elements ---> 29607\n",
      "mean and median spacing 15.810478612949094, 15.727658385209352\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 855])\n",
      "number of elements ---> 30132\n",
      "mean and median spacing 16.353857684013548, 15.931447916615909\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1180])\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n",
      "----------\n",
      "Model ---> vae /home/skambha6/chenlab/tissue_purifier/model_checkpoints/testis/testis_vae.pt\n",
      "----------\n",
      "making encoder resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/skambha6/chenlab/tissue_purifier/tissue_purifier_sk/src/tissue_purifier/models/ssl_models/_resnet_backbone.py:124: UnderReviewWarning: The feature ResNetDecoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  net = ResNetDecoder(DecoderBlock, [3, 4, 6, 3], latent_dim=1,\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/pl_bolts/models/autoencoders/components.py:301: UnderReviewWarning: The feature resize_conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  resize_conv1x1(self.inplanes, planes * block.expansion, scale),\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/pl_bolts/models/autoencoders/components.py:45: UnderReviewWarning: The feature Interpolate is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return nn.Sequential(Interpolate(scale_factor=scale), conv1x1(in_planes, out_planes))\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/pl_bolts/models/autoencoders/components.py:45: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return nn.Sequential(Interpolate(scale_factor=scale), conv1x1(in_planes, out_planes))\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/pl_bolts/models/autoencoders/components.py:306: UnderReviewWarning: The feature DecoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  layers.append(block(self.inplanes, planes, scale, upsample))\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/pl_bolts/models/autoencoders/components.py:132: UnderReviewWarning: The feature resize_conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv1 = resize_conv3x3(inplanes, inplanes)\n",
      "/home/skambha6/miniforge3/envs/tissue_purifier/lib/python3.11/site-packages/pl_bolts/models/autoencoders/components.py:36: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return conv3x3(in_planes, out_planes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements ---> 29178\n",
      "mean and median spacing 15.90507495709278, 15.497339152935078\n",
      "The dense shape of the image is -> torch.Size([9, 1178, 1175])\n",
      "number of elements ---> 27840\n",
      "mean and median spacing 16.009033744023068, 15.768961335552781\n",
      "The dense shape of the image is -> torch.Size([9, 1160, 1143])\n",
      "number of elements ---> 29607\n",
      "mean and median spacing 15.810478612949094, 15.727658385209352\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 855])\n",
      "number of elements ---> 30132\n",
      "mean and median spacing 16.353857684013548, 15.931447916615909\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1180])\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n",
      "number of elements ---> 34868\n",
      "mean and median spacing 15.821949004591055, 15.638433550603624\n",
      "The dense shape of the image is -> torch.Size([9, 1180, 1181])\n"
     ]
    }
   ],
   "source": [
    "from tissue_purifier.data import AnndataFolderDM\n",
    "from tissue_purifier.models.ssl_models import *\n",
    "# now you have access to Barlow, SImclr, Dino, Vae\n",
    "\n",
    "n_patches_max = 1000 # cover each tissue with this many overlapping patches\n",
    "\n",
    "for ckpt_path, model_name in zip(all_ckpts_dest, all_models):\n",
    "    \n",
    "    print(\"----------\")\n",
    "    print(\"Model --->\", model_name, ckpt_path)\n",
    "    print(\"----------\")\n",
    "    \n",
    "    # load the model from checkpoint\n",
    "    if model_name == \"barlow\":\n",
    "        model = tp.models.ssl_models.Barlow.load_from_checkpoint(checkpoint_path=ckpt_path, strict=False)\n",
    "    elif model_name == \"simclr\":\n",
    "        model = tp.models.ssl_models.Simclr.load_from_checkpoint(checkpoint_path=ckpt_path, strict=False)\n",
    "    elif model_name == \"dino\":\n",
    "        model = tp.models.ssl_models.Dino.load_from_checkpoint(checkpoint_path=ckpt_path, strict=False)\n",
    "    elif model_name == \"vae\":\n",
    "        model = tp.models.ssl_models.Vae.load_from_checkpoint(checkpoint_path=ckpt_path, strict=False)\n",
    "    else:\n",
    "        raise Exception(\"Model name not recongnized {}\".format(model_name))\n",
    "        \n",
    "    # create the datamodule associated with the pretrained model\n",
    "    dm = tp.data.AnndataFolderDM(**model._hparams) \n",
    "    \n",
    "    # put the model on GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # process all the anndata with the model-datamodule pair\n",
    "    for fname in fname_list:\n",
    "        \n",
    "        # open adata and convert to sparse_image\n",
    "        adata_path = os.path.join(new_data_destination_folder, fname)\n",
    "        adata = read_h5ad(adata_path)\n",
    "        sp_img = dm.anndata_to_sparseimage(adata)\n",
    "                \n",
    "        # put sparse image on GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            sp_img = sp_img.cuda()\n",
    "            \n",
    "        # compute nvc with different k\n",
    "        if model_name == \"barlow\":\n",
    "            for k in 10, 20, 50, 100, 200, 500:\n",
    "                sp_img.compute_ncv(feature_name=\"ncv_k{}\".format(k), k=k)\n",
    "        \n",
    "        # compute the patch-feature (internally it crops sparse image and feed crops to pretrained model)\n",
    "        sp_img.compute_patch_features(\n",
    "            feature_name=model_name, \n",
    "            datamodule=dm, \n",
    "            model=model, \n",
    "            batch_size=64,\n",
    "            strategy='random',\n",
    "            remove_overlap=False,\n",
    "            n_patches_max=n_patches_max,\n",
    "            overwrite=True)\n",
    "        \n",
    "        # transfer the patch-level annotation to the spot-level\n",
    "        sp_img.transfer_patch_to_spot(keys_to_transfer=model_name, overwrite=True)\n",
    "        \n",
    "        # write the new adata to disk\n",
    "        new_adata = sp_img.to_anndata()\n",
    "        new_adata.write(filename=adata_path) # overwrite the file but with extra annotations \n",
    "        \n",
    "        # free memory by erasing the sparse_image\n",
    "        del sp_img\n",
    "    \n",
    "    # after loop over anndata erase the model and free memory\n",
    "    del model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8f276-76e2-4fa1-80b1-f6fb115f0282",
   "metadata": {},
   "source": [
    "### check that the anndata object have the new annotations stored in .obsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3f3c483-75c8-46bc-98ed-c256e827ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "wt3_dm.h5ad\n",
      "AnnData object with n_obs × n_vars = 29178 × 24450\n",
      "    obs: 'x', 'y', 'UMI', 'cell_type'\n",
      "    uns: 'status'\n",
      "    obsm: 'barlow', 'cell_type_proportions', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'\n",
      "----\n",
      "wt1_dm.h5ad\n",
      "AnnData object with n_obs × n_vars = 27840 × 23514\n",
      "    obs: 'x', 'y', 'UMI', 'cell_type'\n",
      "    uns: 'status'\n",
      "    obsm: 'barlow', 'cell_type_proportions', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'\n",
      "----\n",
      "diabetes2_dm.h5ad\n",
      "AnnData object with n_obs × n_vars = 29607 × 23741\n",
      "    obs: 'x', 'y', 'UMI', 'cell_type'\n",
      "    uns: 'status'\n",
      "    obsm: 'barlow', 'cell_type_proportions', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'\n",
      "----\n",
      "wt2_dm.h5ad\n",
      "AnnData object with n_obs × n_vars = 30132 × 24263\n",
      "    obs: 'x', 'y', 'UMI', 'cell_type'\n",
      "    uns: 'status'\n",
      "    obsm: 'barlow', 'cell_type_proportions', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'\n",
      "----\n",
      "diabetes1_dm.h5ad\n",
      "AnnData object with n_obs × n_vars = 34868 × 23536\n",
      "    obs: 'x', 'y', 'UMI', 'cell_type'\n",
      "    uns: 'status'\n",
      "    obsm: 'barlow', 'cell_type_proportions', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'\n",
      "----\n",
      "diabetes3_dm.h5ad\n",
      "AnnData object with n_obs × n_vars = 34868 × 23536\n",
      "    obs: 'x', 'y', 'UMI', 'cell_type'\n",
      "    uns: 'status'\n",
      "    obsm: 'barlow', 'cell_type_proportions', 'dino', 'ncv_k10', 'ncv_k100', 'ncv_k20', 'ncv_k200', 'ncv_k50', 'ncv_k500', 'simclr', 'vae'\n"
     ]
    }
   ],
   "source": [
    "for fname in fname_list:\n",
    "    anndata = read_h5ad(os.path.join(new_data_destination_folder, fname))\n",
    "    print(\"----\")\n",
    "    print(fname)\n",
    "    print(anndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029c715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
